{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers import BatchNormalization, Activation, ZeroPadding2D\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.convolutional import UpSampling2D, Conv2D\n",
    "from keras.models import Sequential, Model\n",
    "from keras.optimizers import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.misc import imread,imresize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dir = \"1/\"\n",
    "img_list = os.listdir(img_dir)\n",
    "\n",
    "data = []\n",
    "for image_item in img_list:\n",
    "    data.append(imread(img_dir+image_item)/255.)\n",
    "\n",
    "data = np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_11 (Flatten)         (None, 27648)             0         \n",
      "_________________________________________________________________\n",
      "dense_71 (Dense)             (None, 512)               14156288  \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_51 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_72 (Dense)             (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_52 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_73 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 14,287,873\n",
      "Trainable params: 14,287,873\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_74 (Dense)             (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_53 (LeakyReLU)   (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dense_75 (Dense)             (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_54 (LeakyReLU)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dense_76 (Dense)             (None, 1024)              525312    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_55 (LeakyReLU)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 1024)              4096      \n",
      "_________________________________________________________________\n",
      "dense_77 (Dense)             (None, 27648)             28339200  \n",
      "_________________________________________________________________\n",
      "reshape_11 (Reshape)         (None, 96, 96, 3)         0         \n",
      "=================================================================\n",
      "Total params: 29,029,120\n",
      "Trainable params: 29,025,536\n",
      "Non-trainable params: 3,584\n",
      "_________________________________________________________________\n",
      "0 [D loss: 1.025708, acc.: 18.75%] [G loss: 0.688360]\n",
      "1 [D loss: 0.437918, acc.: 65.62%] [G loss: 0.662013]\n",
      "2 [D loss: 0.372296, acc.: 65.62%] [G loss: 0.659445]\n",
      "3 [D loss: 0.353671, acc.: 75.00%] [G loss: 0.665162]\n",
      "4 [D loss: 0.347748, acc.: 78.12%] [G loss: 0.675678]\n",
      "5 [D loss: 0.352541, acc.: 75.00%] [G loss: 0.653538]\n",
      "6 [D loss: 0.355972, acc.: 65.62%] [G loss: 0.676073]\n",
      "7 [D loss: 0.350374, acc.: 71.88%] [G loss: 0.665479]\n",
      "8 [D loss: 0.359442, acc.: 68.75%] [G loss: 0.651201]\n",
      "9 [D loss: 0.353983, acc.: 71.88%] [G loss: 0.672473]\n",
      "10 [D loss: 0.354518, acc.: 71.88%] [G loss: 0.684753]\n",
      "11 [D loss: 0.368643, acc.: 68.75%] [G loss: 0.688549]\n",
      "12 [D loss: 0.362174, acc.: 71.88%] [G loss: 0.706071]\n",
      "13 [D loss: 0.364407, acc.: 71.88%] [G loss: 0.690065]\n",
      "14 [D loss: 0.368700, acc.: 68.75%] [G loss: 0.702779]\n",
      "15 [D loss: 0.340620, acc.: 75.00%] [G loss: 0.702785]\n",
      "16 [D loss: 0.362310, acc.: 68.75%] [G loss: 0.700194]\n",
      "17 [D loss: 0.359547, acc.: 78.12%] [G loss: 0.708390]\n",
      "18 [D loss: 0.371142, acc.: 62.50%] [G loss: 0.741254]\n",
      "19 [D loss: 0.338278, acc.: 68.75%] [G loss: 0.725845]\n",
      "20 [D loss: 0.338236, acc.: 87.50%] [G loss: 0.740133]\n",
      "21 [D loss: 0.352062, acc.: 75.00%] [G loss: 0.739323]\n",
      "22 [D loss: 0.352944, acc.: 75.00%] [G loss: 0.752919]\n",
      "23 [D loss: 0.358277, acc.: 71.88%] [G loss: 0.753269]\n",
      "24 [D loss: 0.338312, acc.: 81.25%] [G loss: 0.761230]\n",
      "25 [D loss: 0.327815, acc.: 78.12%] [G loss: 0.765710]\n",
      "26 [D loss: 0.312493, acc.: 84.38%] [G loss: 0.780591]\n",
      "27 [D loss: 0.300917, acc.: 84.38%] [G loss: 0.793015]\n",
      "28 [D loss: 0.281517, acc.: 100.00%] [G loss: 0.788543]\n",
      "29 [D loss: 0.304713, acc.: 90.62%] [G loss: 0.817221]\n",
      "30 [D loss: 0.285013, acc.: 96.88%] [G loss: 0.803910]\n",
      "31 [D loss: 0.299217, acc.: 90.62%] [G loss: 0.811755]\n",
      "32 [D loss: 0.275315, acc.: 93.75%] [G loss: 0.827303]\n",
      "33 [D loss: 0.311978, acc.: 87.50%] [G loss: 0.824366]\n",
      "34 [D loss: 0.281460, acc.: 93.75%] [G loss: 0.845411]\n",
      "35 [D loss: 0.272598, acc.: 96.88%] [G loss: 0.866799]\n",
      "36 [D loss: 0.290635, acc.: 93.75%] [G loss: 0.875652]\n",
      "37 [D loss: 0.286174, acc.: 93.75%] [G loss: 0.852096]\n",
      "38 [D loss: 0.299264, acc.: 93.75%] [G loss: 0.878478]\n",
      "39 [D loss: 0.258668, acc.: 96.88%] [G loss: 0.875731]\n",
      "40 [D loss: 0.280588, acc.: 90.62%] [G loss: 0.878585]\n",
      "41 [D loss: 0.289075, acc.: 87.50%] [G loss: 0.904704]\n",
      "42 [D loss: 0.262150, acc.: 96.88%] [G loss: 0.913946]\n",
      "43 [D loss: 0.274843, acc.: 96.88%] [G loss: 0.924577]\n",
      "44 [D loss: 0.257378, acc.: 96.88%] [G loss: 0.919510]\n",
      "45 [D loss: 0.234108, acc.: 100.00%] [G loss: 0.914497]\n",
      "46 [D loss: 0.289902, acc.: 96.88%] [G loss: 0.934835]\n",
      "47 [D loss: 0.246058, acc.: 100.00%] [G loss: 0.956446]\n",
      "48 [D loss: 0.226115, acc.: 100.00%] [G loss: 0.919288]\n",
      "49 [D loss: 0.259569, acc.: 96.88%] [G loss: 0.940141]\n",
      "50 [D loss: 0.250970, acc.: 96.88%] [G loss: 0.971454]\n",
      "51 [D loss: 0.239803, acc.: 96.88%] [G loss: 0.976416]\n",
      "52 [D loss: 0.232230, acc.: 100.00%] [G loss: 0.982048]\n",
      "53 [D loss: 0.224261, acc.: 100.00%] [G loss: 0.990421]\n",
      "54 [D loss: 0.245401, acc.: 96.88%] [G loss: 0.996383]\n",
      "55 [D loss: 0.212559, acc.: 100.00%] [G loss: 0.981686]\n",
      "56 [D loss: 0.244908, acc.: 96.88%] [G loss: 0.982799]\n",
      "57 [D loss: 0.252399, acc.: 100.00%] [G loss: 0.994737]\n",
      "58 [D loss: 0.248779, acc.: 100.00%] [G loss: 1.003019]\n",
      "59 [D loss: 0.246309, acc.: 100.00%] [G loss: 1.024850]\n",
      "60 [D loss: 0.237354, acc.: 100.00%] [G loss: 1.024905]\n",
      "61 [D loss: 0.223577, acc.: 100.00%] [G loss: 1.004869]\n",
      "62 [D loss: 0.215393, acc.: 96.88%] [G loss: 1.040266]\n",
      "63 [D loss: 0.225124, acc.: 100.00%] [G loss: 1.020755]\n",
      "64 [D loss: 0.215721, acc.: 100.00%] [G loss: 1.056878]\n",
      "65 [D loss: 0.199183, acc.: 100.00%] [G loss: 1.052407]\n",
      "66 [D loss: 0.221485, acc.: 100.00%] [G loss: 1.044194]\n",
      "67 [D loss: 0.218271, acc.: 100.00%] [G loss: 1.047414]\n",
      "68 [D loss: 0.224361, acc.: 100.00%] [G loss: 1.059060]\n",
      "69 [D loss: 0.206165, acc.: 100.00%] [G loss: 1.077817]\n",
      "70 [D loss: 0.216744, acc.: 100.00%] [G loss: 1.059098]\n",
      "71 [D loss: 0.212979, acc.: 100.00%] [G loss: 1.107718]\n",
      "72 [D loss: 0.194888, acc.: 100.00%] [G loss: 1.063960]\n",
      "73 [D loss: 0.224752, acc.: 100.00%] [G loss: 1.077168]\n",
      "74 [D loss: 0.206369, acc.: 100.00%] [G loss: 1.095459]\n",
      "75 [D loss: 0.209515, acc.: 100.00%] [G loss: 1.116603]\n",
      "76 [D loss: 0.197897, acc.: 100.00%] [G loss: 1.090223]\n",
      "77 [D loss: 0.206254, acc.: 100.00%] [G loss: 1.098945]\n",
      "78 [D loss: 0.192946, acc.: 100.00%] [G loss: 1.108898]\n",
      "79 [D loss: 0.208318, acc.: 100.00%] [G loss: 1.098901]\n",
      "80 [D loss: 0.211093, acc.: 100.00%] [G loss: 1.102784]\n",
      "81 [D loss: 0.204228, acc.: 100.00%] [G loss: 1.128612]\n",
      "82 [D loss: 0.186537, acc.: 100.00%] [G loss: 1.164793]\n",
      "83 [D loss: 0.191614, acc.: 100.00%] [G loss: 1.131076]\n",
      "84 [D loss: 0.207497, acc.: 100.00%] [G loss: 1.131017]\n",
      "85 [D loss: 0.191201, acc.: 100.00%] [G loss: 1.156781]\n",
      "86 [D loss: 0.202022, acc.: 100.00%] [G loss: 1.152145]\n",
      "87 [D loss: 0.187465, acc.: 100.00%] [G loss: 1.179601]\n",
      "88 [D loss: 0.186443, acc.: 100.00%] [G loss: 1.192773]\n",
      "89 [D loss: 0.184461, acc.: 100.00%] [G loss: 1.156528]\n",
      "90 [D loss: 0.191986, acc.: 100.00%] [G loss: 1.182997]\n",
      "91 [D loss: 0.199805, acc.: 100.00%] [G loss: 1.178853]\n",
      "92 [D loss: 0.209952, acc.: 100.00%] [G loss: 1.178958]\n",
      "93 [D loss: 0.195631, acc.: 100.00%] [G loss: 1.206638]\n",
      "94 [D loss: 0.180175, acc.: 100.00%] [G loss: 1.207799]\n",
      "95 [D loss: 0.162382, acc.: 100.00%] [G loss: 1.189859]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96 [D loss: 0.191845, acc.: 100.00%] [G loss: 1.193850]\n",
      "97 [D loss: 0.186817, acc.: 100.00%] [G loss: 1.218528]\n",
      "98 [D loss: 0.158768, acc.: 100.00%] [G loss: 1.195864]\n",
      "99 [D loss: 0.183891, acc.: 100.00%] [G loss: 1.215914]\n",
      "100 [D loss: 0.180812, acc.: 100.00%] [G loss: 1.226646]\n",
      "101 [D loss: 0.178444, acc.: 100.00%] [G loss: 1.224663]\n",
      "102 [D loss: 0.155359, acc.: 100.00%] [G loss: 1.218086]\n",
      "103 [D loss: 0.168081, acc.: 100.00%] [G loss: 1.210349]\n",
      "104 [D loss: 0.161406, acc.: 100.00%] [G loss: 1.251261]\n",
      "105 [D loss: 0.153344, acc.: 100.00%] [G loss: 1.206990]\n",
      "106 [D loss: 0.158372, acc.: 100.00%] [G loss: 1.222871]\n",
      "107 [D loss: 0.152286, acc.: 100.00%] [G loss: 1.249044]\n",
      "108 [D loss: 0.174860, acc.: 100.00%] [G loss: 1.260534]\n",
      "109 [D loss: 0.168592, acc.: 100.00%] [G loss: 1.241065]\n",
      "110 [D loss: 0.158168, acc.: 100.00%] [G loss: 1.256735]\n",
      "111 [D loss: 0.179204, acc.: 100.00%] [G loss: 1.240166]\n",
      "112 [D loss: 0.168845, acc.: 100.00%] [G loss: 1.269057]\n",
      "113 [D loss: 0.179691, acc.: 100.00%] [G loss: 1.248804]\n",
      "114 [D loss: 0.162815, acc.: 100.00%] [G loss: 1.298156]\n",
      "115 [D loss: 0.184986, acc.: 100.00%] [G loss: 1.235075]\n",
      "116 [D loss: 0.175599, acc.: 100.00%] [G loss: 1.258485]\n",
      "117 [D loss: 0.166418, acc.: 100.00%] [G loss: 1.278583]\n",
      "118 [D loss: 0.164526, acc.: 100.00%] [G loss: 1.305520]\n",
      "119 [D loss: 0.158117, acc.: 100.00%] [G loss: 1.264639]\n",
      "120 [D loss: 0.162019, acc.: 100.00%] [G loss: 1.271528]\n",
      "121 [D loss: 0.164069, acc.: 100.00%] [G loss: 1.302296]\n",
      "122 [D loss: 0.172424, acc.: 100.00%] [G loss: 1.292798]\n",
      "123 [D loss: 0.153696, acc.: 100.00%] [G loss: 1.261600]\n",
      "124 [D loss: 0.156434, acc.: 100.00%] [G loss: 1.263053]\n",
      "125 [D loss: 0.170810, acc.: 100.00%] [G loss: 1.299361]\n",
      "126 [D loss: 0.172600, acc.: 100.00%] [G loss: 1.325270]\n",
      "127 [D loss: 0.168610, acc.: 100.00%] [G loss: 1.274932]\n",
      "128 [D loss: 0.170575, acc.: 100.00%] [G loss: 1.312891]\n",
      "129 [D loss: 0.161273, acc.: 100.00%] [G loss: 1.304514]\n",
      "130 [D loss: 0.157975, acc.: 100.00%] [G loss: 1.320737]\n",
      "131 [D loss: 0.169491, acc.: 100.00%] [G loss: 1.289497]\n",
      "132 [D loss: 0.181617, acc.: 100.00%] [G loss: 1.321973]\n",
      "133 [D loss: 0.160660, acc.: 100.00%] [G loss: 1.327181]\n",
      "134 [D loss: 0.161542, acc.: 100.00%] [G loss: 1.358709]\n",
      "135 [D loss: 0.147276, acc.: 100.00%] [G loss: 1.316512]\n",
      "136 [D loss: 0.150368, acc.: 100.00%] [G loss: 1.306180]\n",
      "137 [D loss: 0.179026, acc.: 100.00%] [G loss: 1.342842]\n",
      "138 [D loss: 0.167238, acc.: 100.00%] [G loss: 1.358199]\n",
      "139 [D loss: 0.159095, acc.: 100.00%] [G loss: 1.346961]\n",
      "140 [D loss: 0.152388, acc.: 100.00%] [G loss: 1.325503]\n",
      "141 [D loss: 0.143786, acc.: 100.00%] [G loss: 1.331099]\n",
      "142 [D loss: 0.154447, acc.: 100.00%] [G loss: 1.367408]\n",
      "143 [D loss: 0.158238, acc.: 100.00%] [G loss: 1.362484]\n",
      "144 [D loss: 0.147864, acc.: 100.00%] [G loss: 1.366035]\n",
      "145 [D loss: 0.144843, acc.: 100.00%] [G loss: 1.376689]\n",
      "146 [D loss: 0.143864, acc.: 100.00%] [G loss: 1.348614]\n",
      "147 [D loss: 0.147428, acc.: 100.00%] [G loss: 1.360843]\n",
      "148 [D loss: 0.149447, acc.: 100.00%] [G loss: 1.334236]\n",
      "149 [D loss: 0.163135, acc.: 100.00%] [G loss: 1.363066]\n",
      "150 [D loss: 0.156985, acc.: 100.00%] [G loss: 1.383703]\n",
      "151 [D loss: 0.131198, acc.: 100.00%] [G loss: 1.373512]\n",
      "152 [D loss: 0.148615, acc.: 100.00%] [G loss: 1.386233]\n",
      "153 [D loss: 0.153252, acc.: 100.00%] [G loss: 1.344126]\n",
      "154 [D loss: 0.140276, acc.: 100.00%] [G loss: 1.395640]\n",
      "155 [D loss: 0.153958, acc.: 100.00%] [G loss: 1.390297]\n",
      "156 [D loss: 0.162304, acc.: 100.00%] [G loss: 1.369561]\n",
      "157 [D loss: 0.155764, acc.: 100.00%] [G loss: 1.371108]\n",
      "158 [D loss: 0.136021, acc.: 100.00%] [G loss: 1.351026]\n",
      "159 [D loss: 0.145997, acc.: 100.00%] [G loss: 1.361359]\n",
      "160 [D loss: 0.151072, acc.: 100.00%] [G loss: 1.394938]\n",
      "161 [D loss: 0.142045, acc.: 100.00%] [G loss: 1.377555]\n",
      "162 [D loss: 0.135918, acc.: 100.00%] [G loss: 1.406417]\n",
      "163 [D loss: 0.151694, acc.: 100.00%] [G loss: 1.403972]\n",
      "164 [D loss: 0.154550, acc.: 100.00%] [G loss: 1.386330]\n",
      "165 [D loss: 0.149766, acc.: 100.00%] [G loss: 1.414332]\n",
      "166 [D loss: 0.144557, acc.: 100.00%] [G loss: 1.380673]\n",
      "167 [D loss: 0.141275, acc.: 100.00%] [G loss: 1.398454]\n",
      "168 [D loss: 0.146003, acc.: 100.00%] [G loss: 1.385687]\n",
      "169 [D loss: 0.150373, acc.: 100.00%] [G loss: 1.403082]\n",
      "170 [D loss: 0.147889, acc.: 100.00%] [G loss: 1.407029]\n",
      "171 [D loss: 0.145733, acc.: 100.00%] [G loss: 1.421017]\n",
      "172 [D loss: 0.152358, acc.: 100.00%] [G loss: 1.399968]\n",
      "173 [D loss: 0.144564, acc.: 100.00%] [G loss: 1.391368]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-d30713241d74>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    151\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m     \u001b[0mgan\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m     \u001b[0mgan\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_interval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-30-d30713241d74>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, data, epochs, batch_size, save_interval)\u001b[0m\n\u001b[0;32m    120\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m             \u001b[1;31m# Train the generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 122\u001b[1;33m             \u001b[0mg_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcombined\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnoise\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m             \u001b[1;31m# Plot the progress\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1760\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1761\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1762\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1763\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1764\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[0;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2273\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2274\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    788\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 789\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    790\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    791\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    995\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    996\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m--> 997\u001b[1;33m                              feed_dict_string, options, run_metadata)\n\u001b[0m\u001b[0;32m    998\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    999\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1130\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m       return self._do_call(_run_fn, self._session, feed_dict, fetch_list,\n\u001b[1;32m-> 1132\u001b[1;33m                            target_list, options, run_metadata)\n\u001b[0m\u001b[0;32m   1133\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       return self._do_call(_prun_fn, self._session, handle, feed_dict,\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1137\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1138\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1139\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1140\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1119\u001b[0m         return tf_session.TF_Run(session, options,\n\u001b[0;32m   1120\u001b[0m                                  \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1121\u001b[1;33m                                  status, run_metadata)\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msession\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class GAN():\n",
    "    def __init__(self):\n",
    "        self.img_rows = 96 \n",
    "        self.img_cols = 96\n",
    "        self.channels = 3\n",
    "        self.img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "\n",
    "        optimizer = SGD(lr=3e-4, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "\n",
    "        # Build and compile the discriminator\n",
    "        self.discriminator = self.build_discriminator()\n",
    "        self.discriminator.compile(loss='binary_crossentropy', \n",
    "            optimizer=optimizer,\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "        # Build and compile the generator\n",
    "        self.generator = self.build_generator()\n",
    "        self.generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "        # The generator takes noise as input and generated imgs\n",
    "        z = Input(shape=(100,))\n",
    "        img = self.generator(z)\n",
    "\n",
    "        # For the combined model we will only train the generator\n",
    "        self.discriminator.trainable = False\n",
    "\n",
    "        # The valid takes generated images as input and determines validity\n",
    "        valid = self.discriminator(img)\n",
    "\n",
    "        # The combined model  (stacked generator and discriminator) takes\n",
    "        # noise as input => generates images => determines validity \n",
    "        self.combined = Model(z, valid)\n",
    "        self.combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "    def build_generator(self):\n",
    "\n",
    "        noise_shape = (100,)\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Dense(256, input_shape=noise_shape))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(1024))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(BatchNormalization(momentum=0.8))\n",
    "        model.add(Dense(np.prod(self.img_shape), activation='tanh'))\n",
    "        model.add(Reshape(self.img_shape))\n",
    "\n",
    "        model.summary()\n",
    "\n",
    "        noise = Input(shape=noise_shape)\n",
    "        img = model(noise)\n",
    "\n",
    "        return Model(noise, img)\n",
    "\n",
    "    def build_discriminator(self):\n",
    "\n",
    "        img_shape = (self.img_rows, self.img_cols, self.channels)\n",
    "        \n",
    "        model = Sequential()\n",
    "\n",
    "        model.add(Flatten(input_shape=img_shape))\n",
    "        model.add(Dense(512))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(256))\n",
    "        model.add(LeakyReLU(alpha=0.2))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        model.summary()\n",
    "\n",
    "        img = Input(shape=img_shape)\n",
    "        validity = model(img)\n",
    "\n",
    "        return Model(img, validity)\n",
    "\n",
    "    def train(self,data, epochs, batch_size=128, save_interval=50):\n",
    "\n",
    "        # Load the dataset\n",
    "        X_train = data\n",
    "\n",
    "        # Rescale -1 to 1\n",
    "#         X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "#         X_train = np.expand_dims(X_train, axis=3)\n",
    "\n",
    "        half_batch = int(batch_size / 2)\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Discriminator\n",
    "            # ---------------------\n",
    "\n",
    "            # Select a random half batch of images\n",
    "            idx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "            imgs = X_train[idx]\n",
    "\n",
    "            noise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "            # Generate a half batch of new images\n",
    "            gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "            # Train the discriminator\n",
    "            d_loss_real = self.discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "            d_loss_fake = self.discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "\n",
    "            # ---------------------\n",
    "            #  Train Generator\n",
    "            # ---------------------\n",
    "\n",
    "            noise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "            # The generator wants the discriminator to label the generated samples\n",
    "            # as valid (ones)\n",
    "            valid_y = np.array([1] * batch_size)\n",
    "\n",
    "            # Train the generator\n",
    "            g_loss = self.combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "            # Plot the progress\n",
    "            print (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "            # If at save interval => save generated image samples\n",
    "            if epoch % save_interval == 0:\n",
    "                self.save_imgs(epoch)\n",
    "\n",
    "    def save_imgs(self, epoch):\n",
    "        r, c = 5, 5\n",
    "        noise = np.random.normal(0, 1, (r * c, 100))\n",
    "        gen_imgs = self.generator.predict(noise)\n",
    "\n",
    "        # Rescale images 0 - 1\n",
    "        gen_imgs = gen_imgs*0.5 + 0.5\n",
    "#         print(gen_imgs)\n",
    "\n",
    "        fig, axs = plt.subplots(r, c)\n",
    "        cnt = 0\n",
    "        for i in range(r):\n",
    "            for j in range(c):\n",
    "                axs[i,j].imshow(gen_imgs[cnt, :,:,:])\n",
    "                axs[i,j].axis('off')\n",
    "                cnt += 1\n",
    "        fig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    gan = GAN()\n",
    "    gan.train(data=data,epochs=30000, batch_size=32, save_interval=200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cv2.imshow(\"hehe\",(data[1]*255).astype(\"uint8\"))\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow(\"hehe\",data[1])\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[106, 117, 139],\n",
       "        [113, 124, 146],\n",
       "        [139, 147, 170],\n",
       "        ..., \n",
       "        [ 98, 100, 121],\n",
       "        [116, 118, 139],\n",
       "        [142, 143, 164]],\n",
       "\n",
       "       [[118, 129, 151],\n",
       "        [150, 158, 181],\n",
       "        [147, 155, 178],\n",
       "        ..., \n",
       "        [113, 115, 138],\n",
       "        [122, 124, 145],\n",
       "        [129, 131, 152]],\n",
       "\n",
       "       [[122, 129, 155],\n",
       "        [151, 159, 182],\n",
       "        [141, 149, 172],\n",
       "        ..., \n",
       "        [138, 140, 163],\n",
       "        [122, 124, 147],\n",
       "        [106, 108, 129]],\n",
       "\n",
       "       ..., \n",
       "       [[119, 124, 146],\n",
       "        [ 98, 103, 125],\n",
       "        [106, 111, 133],\n",
       "        ..., \n",
       "        [114, 119, 141],\n",
       "        [118, 123, 145],\n",
       "        [121, 126, 148]],\n",
       "\n",
       "       [[106, 111, 133],\n",
       "        [ 91,  96, 118],\n",
       "        [101, 106, 128],\n",
       "        ..., \n",
       "        [111, 116, 138],\n",
       "        [104, 109, 131],\n",
       "        [106, 111, 133]],\n",
       "\n",
       "       [[ 86,  91, 113],\n",
       "        [ 92,  97, 119],\n",
       "        [102, 107, 129],\n",
       "        ..., \n",
       "        [116, 121, 143],\n",
       "        [108, 113, 135],\n",
       "        [133, 138, 160]]], dtype=uint8)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data[1]*255).astype(\"uint8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[170, 165, 143],\n",
       "         [189, 184, 162],\n",
       "         [171, 166, 144],\n",
       "         ..., \n",
       "         [152, 147, 125],\n",
       "         [132, 126, 104],\n",
       "         [139, 133, 111]],\n",
       "\n",
       "        [[148, 143, 121],\n",
       "         [128, 123, 101],\n",
       "         [100,  95,  73],\n",
       "         ..., \n",
       "         [154, 149, 127],\n",
       "         [127, 122, 100],\n",
       "         [141, 135, 113]],\n",
       "\n",
       "        [[139, 134, 112],\n",
       "         [116, 111,  89],\n",
       "         [120, 115,  93],\n",
       "         ..., \n",
       "         [148, 143, 121],\n",
       "         [124, 119,  97],\n",
       "         [139, 133, 111]],\n",
       "\n",
       "        ..., \n",
       "        [[134, 132, 109],\n",
       "         [141, 136, 114],\n",
       "         [149, 145, 120],\n",
       "         ..., \n",
       "         [159, 154, 132],\n",
       "         [158, 153, 131],\n",
       "         [143, 138, 116]],\n",
       "\n",
       "        [[138, 136, 113],\n",
       "         [133, 129, 104],\n",
       "         [150, 146, 121],\n",
       "         ..., \n",
       "         [150, 145, 123],\n",
       "         [128, 123, 101],\n",
       "         [126, 121,  99]],\n",
       "\n",
       "        [[136, 134, 111],\n",
       "         [138, 136, 111],\n",
       "         [139, 135, 110],\n",
       "         ..., \n",
       "         [134, 129, 107],\n",
       "         [123, 118,  96],\n",
       "         [149, 144, 122]]],\n",
       "\n",
       "\n",
       "       [[[150, 139, 117],\n",
       "         [143, 132, 110],\n",
       "         [117, 109,  86],\n",
       "         ..., \n",
       "         [158, 156, 135],\n",
       "         [140, 138, 117],\n",
       "         [114, 113,  92]],\n",
       "\n",
       "        [[138, 127, 105],\n",
       "         [106,  98,  75],\n",
       "         [109, 101,  78],\n",
       "         ..., \n",
       "         [143, 141, 118],\n",
       "         [134, 132, 111],\n",
       "         [127, 125, 104]],\n",
       "\n",
       "        [[134, 127, 101],\n",
       "         [105,  97,  74],\n",
       "         [115, 107,  84],\n",
       "         ..., \n",
       "         [118, 116,  93],\n",
       "         [134, 132, 109],\n",
       "         [150, 148, 127]],\n",
       "\n",
       "        ..., \n",
       "        [[137, 132, 110],\n",
       "         [158, 153, 131],\n",
       "         [150, 145, 123],\n",
       "         ..., \n",
       "         [142, 137, 115],\n",
       "         [138, 133, 111],\n",
       "         [135, 130, 108]],\n",
       "\n",
       "        [[150, 145, 123],\n",
       "         [165, 160, 138],\n",
       "         [155, 150, 128],\n",
       "         ..., \n",
       "         [145, 140, 118],\n",
       "         [152, 147, 125],\n",
       "         [150, 145, 123]],\n",
       "\n",
       "        [[170, 165, 143],\n",
       "         [164, 159, 137],\n",
       "         [154, 149, 127],\n",
       "         ..., \n",
       "         [140, 135, 113],\n",
       "         [148, 143, 121],\n",
       "         [123, 118,  96]]],\n",
       "\n",
       "\n",
       "       [[[ 51,  48,  39],\n",
       "         [ 61,  59,  47],\n",
       "         [ 70,  68,  56],\n",
       "         ..., \n",
       "         [209, 215, 205],\n",
       "         [194, 200, 190],\n",
       "         [168, 174, 164]],\n",
       "\n",
       "        [[117, 115, 103],\n",
       "         [121, 119, 107],\n",
       "         [126, 126, 114],\n",
       "         ..., \n",
       "         [211, 217, 207],\n",
       "         [203, 209, 199],\n",
       "         [194, 200, 190]],\n",
       "\n",
       "        [[155, 153, 141],\n",
       "         [143, 143, 131],\n",
       "         [125, 125, 113],\n",
       "         ..., \n",
       "         [208, 211, 200],\n",
       "         [212, 215, 206],\n",
       "         [196, 199, 190]],\n",
       "\n",
       "        ..., \n",
       "        [[123, 128, 121],\n",
       "         [130, 135, 128],\n",
       "         [137, 142, 135],\n",
       "         ..., \n",
       "         [141, 144, 135],\n",
       "         [162, 165, 156],\n",
       "         [155, 158, 149]],\n",
       "\n",
       "        [[147, 152, 145],\n",
       "         [122, 127, 120],\n",
       "         [129, 134, 127],\n",
       "         ..., \n",
       "         [125, 128, 119],\n",
       "         [135, 138, 129],\n",
       "         [155, 158, 149]],\n",
       "\n",
       "        [[142, 149, 141],\n",
       "         [138, 145, 137],\n",
       "         [128, 133, 126],\n",
       "         ..., \n",
       "         [127, 130, 121],\n",
       "         [139, 142, 133],\n",
       "         [156, 159, 150]]],\n",
       "\n",
       "\n",
       "       ..., \n",
       "       [[[112, 111, 107],\n",
       "         [114, 113, 109],\n",
       "         [109, 108, 104],\n",
       "         ..., \n",
       "         [128, 120, 117],\n",
       "         [112, 102, 100],\n",
       "         [ 93,  83,  81]],\n",
       "\n",
       "        [[110, 109, 105],\n",
       "         [116, 115, 111],\n",
       "         [105, 104, 100],\n",
       "         ..., \n",
       "         [129, 121, 118],\n",
       "         [100,  92,  89],\n",
       "         [ 89,  79,  77]],\n",
       "\n",
       "        [[100,  99,  95],\n",
       "         [106, 105, 101],\n",
       "         [ 99,  98,  94],\n",
       "         ..., \n",
       "         [130, 125, 119],\n",
       "         [105,  97,  94],\n",
       "         [100,  92,  89]],\n",
       "\n",
       "        ..., \n",
       "        [[ 97,  94,  87],\n",
       "         [ 97,  94,  87],\n",
       "         [104, 101,  94],\n",
       "         ..., \n",
       "         [116, 113, 106],\n",
       "         [115, 112, 105],\n",
       "         [118, 113, 107]],\n",
       "\n",
       "        [[112, 109, 104],\n",
       "         [106, 103,  98],\n",
       "         [108, 105,  98],\n",
       "         ..., \n",
       "         [122, 119, 112],\n",
       "         [120, 117, 110],\n",
       "         [122, 117, 111]],\n",
       "\n",
       "        [[113, 110, 105],\n",
       "         [110, 107, 102],\n",
       "         [109, 106, 101],\n",
       "         ..., \n",
       "         [115, 112, 105],\n",
       "         [116, 113, 106],\n",
       "         [129, 124, 118]]],\n",
       "\n",
       "\n",
       "       [[[128, 134, 132],\n",
       "         [122, 128, 124],\n",
       "         [120, 125, 121],\n",
       "         ..., \n",
       "         [115, 117, 112],\n",
       "         [140, 141, 136],\n",
       "         [138, 139, 134]],\n",
       "\n",
       "        [[ 93,  99,  97],\n",
       "         [100, 106, 102],\n",
       "         [ 97, 102,  98],\n",
       "         ..., \n",
       "         [119, 121, 116],\n",
       "         [147, 148, 143],\n",
       "         [125, 126, 121]],\n",
       "\n",
       "        [[ 93,  99,  97],\n",
       "         [ 83,  89,  85],\n",
       "         [ 76,  82,  78],\n",
       "         ..., \n",
       "         [136, 138, 133],\n",
       "         [128, 130, 125],\n",
       "         [119, 121, 116]],\n",
       "\n",
       "        ..., \n",
       "        [[107, 112, 108],\n",
       "         [ 82,  87,  83],\n",
       "         [ 70,  75,  71],\n",
       "         ..., \n",
       "         [126, 131, 127],\n",
       "         [118, 123, 119],\n",
       "         [ 99, 104, 100]],\n",
       "\n",
       "        [[109, 111, 108],\n",
       "         [ 85,  87,  84],\n",
       "         [ 74,  79,  75],\n",
       "         ..., \n",
       "         [109, 111, 108],\n",
       "         [113, 115, 112],\n",
       "         [101, 103, 100]],\n",
       "\n",
       "        [[110, 112, 109],\n",
       "         [ 99, 101,  98],\n",
       "         [ 72,  77,  73],\n",
       "         ..., \n",
       "         [103, 105, 102],\n",
       "         [102, 104,  99],\n",
       "         [ 87,  89,  84]]],\n",
       "\n",
       "\n",
       "       [[[111, 116, 110],\n",
       "         [ 94,  99,  93],\n",
       "         [120, 125, 121],\n",
       "         ..., \n",
       "         [129, 131, 128],\n",
       "         [110, 112, 109],\n",
       "         [109, 109, 107]],\n",
       "\n",
       "        [[108, 113, 107],\n",
       "         [ 95, 100,  94],\n",
       "         [114, 119, 113],\n",
       "         ..., \n",
       "         [135, 137, 134],\n",
       "         [122, 124, 121],\n",
       "         [120, 122, 119]],\n",
       "\n",
       "        [[115, 120, 114],\n",
       "         [107, 112, 106],\n",
       "         [105, 110, 104],\n",
       "         ..., \n",
       "         [124, 126, 123],\n",
       "         [105, 110, 106],\n",
       "         [111, 116, 112]],\n",
       "\n",
       "        ..., \n",
       "        [[ 87,  92,  88],\n",
       "         [ 81,  86,  82],\n",
       "         [ 81,  86,  82],\n",
       "         ..., \n",
       "         [ 85,  91,  89],\n",
       "         [ 89,  95,  95],\n",
       "         [ 84,  88,  89]],\n",
       "\n",
       "        [[ 77,  82,  78],\n",
       "         [ 65,  70,  66],\n",
       "         [ 69,  74,  70],\n",
       "         ..., \n",
       "         [ 82,  88,  86],\n",
       "         [ 83,  87,  88],\n",
       "         [ 83,  87,  88]],\n",
       "\n",
       "        [[ 86,  91,  87],\n",
       "         [ 85,  90,  86],\n",
       "         [ 88,  93,  89],\n",
       "         ..., \n",
       "         [ 82,  88,  86],\n",
       "         [ 81,  85,  86],\n",
       "         [ 85,  89,  90]]]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
